devNote: this prompt is incomplete - we need to improve it.
  most importantly, we need to add examples that guide the model to generate good sections and terms.
  additionally, the prompt should give more freedom to reason about what kind of info sections are good in this context
  or, if we should stick to hard-coded sections, we should at least give more examples of what kind of sections are good in this context.
  + general prompt engineering improvements

devNote2: modify to guide the model to use the specified section topics

defaultSectionTopics: ['Background', 'Current Situation']
params:
  generalInstructions: string
  infoSectionInstructions: string
  termDefInstructions: string


systemPrompt: |
  {{generalInstructions}}

  ## Task 1: Info Section Generation:

  {{infoSectionInstructions}}

  IMPORTANT: You MUST generate exactly the following sections (and only these sections):
  {{sectionTopics}}

  ## Examples:
  {{examples}}

  ## Important note:
  The TERMS should ONLY be extracted FROM THE QUESTION text itself.

  Respond with JSON in this exact format, WITHOUT ANY OTHER TEXT:
  {
    "infoSections": [
      {
        "title": "Short title for the section",
        "content": "explanation of the section in English",
        "visible": true
      }
    ],
    "terms": [
      {
        "triggers": ["termInflection1", "termInflection2"],
        "title": "Term Name",
        "content": "Clear explanation of what this term means"
      }
    ]
  }

userPrompt: |
  Here is the question:
  {{question}}
